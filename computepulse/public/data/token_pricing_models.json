{
  "openai": {
    "gpt_4o": {
      "input_price_per_million": 5.0,
      "output_price_per_million": 15.0,
      "subscription_alternative": {
        "chatgpt_plus": 20.0,
        "monthly_limit": "Usage caps on GPT-4o (e.g., up to 80 messages every 3 hours), unlimited access on GPT-4o mini"
      },
      "efficiency_score": 100.0
    },
    "gpt_4_turbo": {
      "input_price_per_million": 10.0,
      "output_price_per_million": 30.0,
      "subscription_alternative": null,
      "efficiency_score": 50.0
    }
  },
  "anthropic": {
    "claude_3_5_sonnet": {
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "subscription_alternative": {
        "claude_pro": 20.0,
        "monthly_limit": "5x the usage limits of the free tier; approximate limit for Claude 3.5 Sonnet is ~1,000 messages per 8 hours"
      },
      "efficiency_score": 111.11
    }
  },
  "pricing_analysis": {
    "average_input_cost": 6.0,
    "average_output_cost": 20.0,
    "most_efficient": "Claude 3.5 Sonnet",
    "subscription_adoption_rate": null,
    "trend": "The market is experiencing a rapid 'race to the bottom' on token prices, driven by new, highly efficient models. Flagship models from OpenAI and Anthropic are becoming more cost-effective (e.g., GPT-4o vs. GPT-4 Turbo), while a new category of powerful, low-cost challengers like DeepSeek (V3 at ~$0.27/$1.10 per million) and Alibaba's Qwen are setting aggressive new price floors. This is forcing a bifurcation: premium models for complex tasks versus ultra-low-cost models for high-volume, simpler applications. Subscription models (ChatGPT Plus, Claude Pro) remain crucial for consumer access, providing usage-based access to top-tier models at a fixed monthly cost. Meanwhile, the open-source strategy championed by Meta's Llama 3 continues to pressure commercial offerings, as self-hosting eliminates token costs but introduces infrastructure expenses."
  },
  "last_updated": "2024-08-21",
  "timestamp": "2025-12-13T07:14:36.965371"
}