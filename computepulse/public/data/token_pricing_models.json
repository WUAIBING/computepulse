{
  "openai": {
    "gpt_4o": {
      "input_price_per_million": 5.0,
      "output_price_per_million": 15.0,
      "subscription_alternative": {
        "chatgpt_plus": 20.0,
        "monthly_limit": "Up to 5x more usage than free tier for GPT-4o, with limits resetting every few hours"
      },
      "efficiency_score": 2.0
    },
    "gpt_4_turbo": {
      "input_price_per_million": 10.0,
      "output_price_per_million": 30.0,
      "subscription_alternative": null,
      "efficiency_score": 1.0
    }
  },
  "anthropic": {
    "claude_3_5_sonnet": {
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "subscription_alternative": {
        "claude_pro": 20.0,
        "monthly_limit": "5x more usage than free tier, with a higher maximum spend cap"
      },
      "efficiency_score": 1.2
    }
  },
  "pricing_analysis": {
    "average_input_cost": 6.0,
    "average_output_cost": 20.0,
    "most_efficient": "OpenAI GPT-4o (for tier-1 frontier models)",
    "subscription_adoption_rate": "N/A (Publicly available data not published)",
    "trend": "Aggressive price competition is the dominant trend in 2024, driven by the release of highly efficient open-weight models like Meta's Llama 3 and DeepSeek. Frontier models from OpenAI and Anthropic have significantly cut prices (e.g., GPT-4o is ~50% cheaper than GPT-4 Turbo). There's a bifurcation: consumer products use subscriptions (ChatGPT Plus, Claude Pro) for access with usage limits, while developer/enterprise access is purely pay-per-token. Extremely low-cost models from China (Qwen, DeepSeek) are setting a new baseline for cost-efficiency, forcing western providers to compete on value and performance per dollar, not just capability."
  },
  "last_updated": "2024-05-29",
  "timestamp": "2025-12-11T03:57:34.444064"
}