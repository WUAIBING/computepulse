"""
Real-time Data Fetching with Enhanced Sources
å®æ—¶æ•°æ®æŠ“å– - å¢å¼ºç‰ˆæ•°æ®æº

Features:
- æ¯å°æ—¶æ›´æ–°GPUå‡ºè´§é‡å’Œä»·æ ¼
- å®æ—¶è¿½è¸ªç”µç½‘è´Ÿè½½å’Œç”µä»·
- ç›‘æ§AIè¡Œä¸šæ–°é—»å’Œè´¢æŠ¥
- å¤šç»´åº¦æ•°æ®äº¤å‰éªŒè¯
"""

import sys
import os
import json
import asyncio
from datetime import datetime, timedelta
import time

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from ai_orchestrator import AIOrchestrator, AIModel, TaskType, OrchestratorConfig

# Initialize orchestrator
config = OrchestratorConfig()
orchestrator = AIOrchestrator(config)

# Register AI models
orchestrator.register_model(AIModel(
    name="qwen", provider="Alibaba", cost_per_1m_tokens=0.6, avg_response_time=3.5
))
orchestrator.register_model(AIModel(
    name="deepseek", provider="DeepSeek", cost_per_1m_tokens=0.8, avg_response_time=5.0
))
orchestrator.register_model(AIModel(
    name="doubao", provider="Volcengine", cost_per_1m_tokens=1.2, avg_response_time=15.0
))

# Data paths
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'public', 'data')
os.makedirs(DATA_DIR, exist_ok=True)

REALTIME_DIR = os.path.join(DATA_DIR, 'realtime')
os.makedirs(REALTIME_DIR, exist_ok=True)


async def fetch_gpu_shipment_data():
    """
    æŠ“å–GPUå‡ºè´§é‡æ•°æ® - æ¯å°æ—¶æ›´æ–°
    
    æ•°æ®æº:
    - NVIDIAè´¢æŠ¥å’Œæ–°é—»å‘å¸ƒ
    - AMD/Intel GPUå‡ºè´§æ•°æ®
    - ä¸­å›½AIèŠ¯ç‰‡å‚å•†ï¼ˆåä¸ºã€å¯’æ­¦çºªç­‰ï¼‰
    - äº‘æœåŠ¡å•†é‡‡è´­å…¬å‘Š
    """
    print(f"\n{'='*80}")
    print(f"[{datetime.now()}] ğŸ“¦ Fetching GPU Shipment Data")
    print(f"{'='*80}\n")
    
    prompt = """
    è¯·ä½¿ç”¨è”ç½‘æœç´¢åŠŸèƒ½ï¼ŒæŸ¥æ‰¾ä»¥ä¸‹GPU/AIèŠ¯ç‰‡çš„æœ€æ–°å‡ºè´§é‡å’Œéƒ¨ç½²æ•°æ®ï¼š
    
    1. NVIDIA GPUå‡ºè´§é‡ï¼ˆæœ€è¿‘24å°æ—¶ï¼‰:
       - H100/H200 å‡ºè´§é‡
       - A100 å‡ºè´§é‡
       - ä¸»è¦å®¢æˆ·ï¼šMicrosoft, Google, Meta, Amazon, Tesla, xAIç­‰
    
    2. å…¶ä»–å‚å•†GPUå‡ºè´§:
       - AMD MI300ç³»åˆ—
       - Intel Gaudiç³»åˆ—
    
    3. ä¸­å›½AIèŠ¯ç‰‡å‡ºè´§:
       - åä¸ºæ˜‡è…¾910B/910C
       - å¯’æ­¦çºªMLUç³»åˆ—
       - æµ·å…‰DCU
    
    4. äº‘æœåŠ¡å•†GPUéƒ¨ç½²:
       - AWSæ–°å¢GPUæ•°é‡
       - Google Cloudæ–°å¢TPU/GPU
       - Azureæ–°å¢GPU
       - é˜¿é‡Œäº‘/è…¾è®¯äº‘/ç™¾åº¦äº‘æ–°å¢AIèŠ¯ç‰‡
    
    è¯·æœç´¢æœ€æ–°çš„æ–°é—»ã€è´¢æŠ¥ã€é‡‡è´­å…¬å‘Šï¼Œè¿”å›JSONæ ¼å¼ï¼š
    [
      {
        "timestamp": "2024-12-05T10:00:00Z",
        "vendor": "NVIDIA",
        "model": "H100",
        "shipment_count": 50000,
        "customer": "Microsoft",
        "source": "æ–°é—»æ¥æº",
        "confidence": "high/medium/low"
      }
    ]
    
    è¦æ±‚ï¼š
    - åªè¿”å›JSONï¼Œä¸è¦Markdownæ ‡è®°
    - å¿…é¡»åŸºäºçœŸå®æœç´¢ç»“æœ
    - æ ‡æ³¨æ•°æ®æ¥æºå’Œç½®ä¿¡åº¦
    """
    
    result = await orchestrator.process_request(
        prompt=prompt,
        context={"data_type": "gpu_shipment"},
        quality_threshold=0.7
    )
    
    # Save to file
    output_file = os.path.join(REALTIME_DIR, 'gpu_shipments.json')
    
    # Load existing data
    existing_data = []
    if os.path.exists(output_file):
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        except:
            pass
    
    # Append new data (keep last 168 hours = 7 days)
    if isinstance(result.data, dict) and 'status' not in result.data:
        # Real data from AI
        new_entry = {
            "timestamp": datetime.now().isoformat(),
            "data": result.data,
            "models_used": result.contributing_models,
            "confidence_scores": result.confidence_scores
        }
        existing_data.append(new_entry)
        
        # Keep only last 7 days
        cutoff_time = datetime.now() - timedelta(days=7)
        existing_data = [
            entry for entry in existing_data
            if datetime.fromisoformat(entry["timestamp"]) > cutoff_time
        ]
    
    # Save
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(existing_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… GPU shipment data saved: {len(existing_data)} records")
    return result


async def fetch_active_gpu_count():
    """
    è®¡ç®—å…¨çƒæ´»è·ƒGPUæ€»æ•° - åŸºäºå‡ºè´§é‡å’Œé€€å½¹ç‡
    """
    print(f"\n{'='*80}")
    print(f"[{datetime.now()}] ğŸ”¢ Calculating Active GPU Count")
    print(f"{'='*80}\n")
    
    prompt = """
    è¯·ä½¿ç”¨è”ç½‘æœç´¢åŠŸèƒ½ï¼Œè®¡ç®—å…¨çƒå½“å‰æ´»è·ƒçš„AIè®­ç»ƒGPUæ€»æ•°ã€‚
    
    éœ€è¦è€ƒè™‘çš„å› ç´ ï¼š
    1. å†å²å‡ºè´§é‡ï¼ˆ2020-2024ï¼‰
    2. GPUç”Ÿå‘½å‘¨æœŸï¼ˆé€šå¸¸3-5å¹´ï¼‰
    3. é€€å½¹ç‡ï¼ˆæ¯å¹´çº¦20-30%ï¼‰
    4. ä¸»è¦æ•°æ®ä¸­å¿ƒçš„GPUéƒ¨ç½²æ•°é‡
    
    æœç´¢ä»¥ä¸‹ä¿¡æ¯ï¼š
    - NVIDIAå†å¹´GPUå‡ºè´§é‡
    - ä¸»è¦äº‘æœåŠ¡å•†çš„GPUé›†ç¾¤è§„æ¨¡
    - AIå…¬å¸çš„GPUé‡‡è´­æ•°æ®
    - ç ”ç©¶æœºæ„çš„ä¼°ç®—æŠ¥å‘Š
    
    è¿”å›JSONæ ¼å¼ï¼š
    {
      "total_active_gpus": 5200000,
      "breakdown": {
        "h100": 800000,
        "a100": 2500000,
        "v100": 1200000,
        "others": 700000
      },
      "growth_rate_monthly": 0.08,
      "sources": ["æ¥æº1", "æ¥æº2"],
      "confidence": "high",
      "last_updated": "2024-12-05"
    }
    
    è¦æ±‚ï¼š
    - åŸºäºçœŸå®æœç´¢ç»“æœ
    - æä¾›è®¡ç®—é€»è¾‘
    - æ ‡æ³¨æ•°æ®æ¥æº
    """
    
    result = await orchestrator.process_request(
        prompt=prompt,
        context={"data_type": "active_gpu_count"},
        quality_threshold=0.8
    )
    
    # Save to file
    output_file = os.path.join(REALTIME_DIR, 'active_gpu_count.json')
    
    data_to_save = {
        "timestamp": datetime.now().isoformat(),
        "data": result.data,
        "models_used": result.contributing_models,
        "confidence_scores": result.confidence_scores
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data_to_save, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Active GPU count saved")
    return result


async def fetch_electricity_prices():
    """
    æŠ“å–å®æ—¶ç”µä»·æ•°æ® - æ¯å°æ—¶æ›´æ–°
    
    æ•°æ®æº:
    - å„å›½ç”µç½‘å®æ—¶ç”µä»·
    - æ•°æ®ä¸­å¿ƒæ‰€åœ¨åœ°åŒºç”µä»·
    - å¯å†ç”Ÿèƒ½æºä»·æ ¼
    """
    print(f"\n{'='*80}")
    print(f"[{datetime.now()}] âš¡ Fetching Real-time Electricity Prices")
    print(f"{'='*80}\n")
    
    prompt = """
    è¯·ä½¿ç”¨è”ç½‘æœç´¢åŠŸèƒ½ï¼ŒæŸ¥æ‰¾å…¨çƒä¸»è¦æ•°æ®ä¸­å¿ƒåœ°åŒºçš„å®æ—¶ç”µä»·ã€‚
    
    é‡ç‚¹åœ°åŒºï¼š
    1. ç¾å›½ï¼š
       - å¾·å…‹è¨æ–¯å·ï¼ˆå¤§é‡æ•°æ®ä¸­å¿ƒï¼‰
       - ä¿„å‹’å†ˆå·ï¼ˆAWSã€Googleï¼‰
       - å¼—å‰å°¼äºšå·ï¼ˆAWSæœ€å¤§é›†ç¾¤ï¼‰
       - åŠ å·ï¼ˆå¤šä¸ªAIå…¬å¸ï¼‰
    
    2. æ¬§æ´²ï¼š
       - çˆ±å°”å…°ï¼ˆMetaã€Googleï¼‰
       - è·å…°ï¼ˆå¤šä¸ªæ•°æ®ä¸­å¿ƒï¼‰
       - ç‘å…¸ï¼ˆå¯å†ç”Ÿèƒ½æºï¼‰
    
    3. äºšæ´²ï¼š
       - ä¸­å›½ï¼ˆé˜¿é‡Œäº‘ã€è…¾è®¯äº‘ï¼‰
       - æ–°åŠ å¡ï¼ˆAWSã€Googleï¼‰
       - æ—¥æœ¬ï¼ˆå¤šä¸ªæ•°æ®ä¸­å¿ƒï¼‰
    
    æœç´¢å†…å®¹ï¼š
    - å®æ—¶ç”µä»·ï¼ˆç¾å…ƒ/kWhï¼‰
    - å·¥ä¸šç”¨ç”µä»·æ ¼
    - å³°è°·ç”µä»·å·®å¼‚
    - å¯å†ç”Ÿèƒ½æºå æ¯”
    
    è¿”å›JSONæ ¼å¼ï¼š
    [
      {
        "region": "Texas, USA",
        "price_kwh": 0.085,
        "currency": "USD",
        "timestamp": "2024-12-05T10:00:00Z",
        "peak_price": 0.12,
        "off_peak_price": 0.06,
        "renewable_percentage": 35,
        "source": "ERCOT"
      }
    ]
    
    è¦æ±‚ï¼š
    - å®æ—¶æˆ–æœ€è¿‘24å°æ—¶æ•°æ®
    - æ ‡æ³¨æ•°æ®æ¥æº
    - åŒºåˆ†å³°è°·ç”µä»·
    """
    
    result = await orchestrator.process_request(
        prompt=prompt,
        context={"data_type": "electricity_prices"},
        quality_threshold=0.7
    )
    
    # Save to file
    output_file = os.path.join(REALTIME_DIR, 'electricity_prices.json')
    
    # Load existing data
    existing_data = []
    if os.path.exists(output_file):
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        except:
            pass
    
    # Append new data (keep last 24 hours)
    new_entry = {
        "timestamp": datetime.now().isoformat(),
        "data": result.data,
        "models_used": result.contributing_models
    }
    existing_data.append(new_entry)
    
    # Keep only last 24 hours
    cutoff_time = datetime.now() - timedelta(hours=24)
    existing_data = [
        entry for entry in existing_data
        if datetime.fromisoformat(entry["timestamp"]) > cutoff_time
    ]
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(existing_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Electricity prices saved: {len(existing_data)} hourly records")
    return result


async def fetch_ai_industry_news():
    """
    æŠ“å–AIè¡Œä¸šæ–°é—» - æ¯å°æ—¶æ›´æ–°
    
    å…³æ³¨ï¼š
    - GPUé‡‡è´­å…¬å‘Š
    - æ•°æ®ä¸­å¿ƒå»ºè®¾
    - AIå…¬å¸èèµ„
    - æ”¿ç­–æ³•è§„å˜åŒ–
    """
    print(f"\n{'='*80}")
    print(f"[{datetime.now()}] ğŸ“° Fetching AI Industry News")
    print(f"{'='*80}\n")
    
    prompt = """
    è¯·ä½¿ç”¨è”ç½‘æœç´¢åŠŸèƒ½ï¼ŒæŸ¥æ‰¾æœ€è¿‘24å°æ—¶å†…çš„AIè¡Œä¸šé‡è¦æ–°é—»ã€‚
    
    é‡ç‚¹å…³æ³¨ï¼š
    1. GPU/AIèŠ¯ç‰‡ç›¸å…³ï¼š
       - NVIDIAæ–°äº§å“å‘å¸ƒ
       - å¤§è§„æ¨¡GPUé‡‡è´­å…¬å‘Š
       - AIèŠ¯ç‰‡å‚å•†åŠ¨æ€
    
    2. æ•°æ®ä¸­å¿ƒå»ºè®¾ï¼š
       - æ–°æ•°æ®ä¸­å¿ƒå¼€å·¥/æŠ•äº§
       - æ•°æ®ä¸­å¿ƒæ‰©å®¹è®¡åˆ’
       - èƒ½æºä¾›åº”åè®®
    
    3. AIå…¬å¸åŠ¨æ€ï¼š
       - OpenAI, Anthropic, Google, Metaç­‰
       - å¤§è§„æ¨¡èèµ„
       - ç®—åŠ›é‡‡è´­è®¡åˆ’
    
    4. æ”¿ç­–æ³•è§„ï¼š
       - AIç›‘ç®¡æ”¿ç­–
       - èƒ½æºæ”¿ç­–
       - å‡ºå£ç®¡åˆ¶
    
    è¿”å›JSONæ ¼å¼ï¼š
    [
      {
        "timestamp": "2024-12-05T09:30:00Z",
        "title": "Microsofté‡‡è´­10ä¸‡å¼ H100 GPU",
        "category": "gpu_purchase",
        "impact": "high",
        "summary": "ç®€çŸ­æ‘˜è¦",
        "source": "æ–°é—»æ¥æº",
        "url": "é“¾æ¥"
      }
    ]
    
    è¦æ±‚ï¼š
    - æœ€è¿‘24å°æ—¶æ–°é—»
    - è¯„ä¼°å½±å“ç¨‹åº¦ï¼ˆhigh/medium/lowï¼‰
    - æä¾›æ–°é—»æ¥æº
    """
    
    result = await orchestrator.process_request(
        prompt=prompt,
        context={"data_type": "industry_news"},
        quality_threshold=0.7
    )
    
    # Save to file
    output_file = os.path.join(REALTIME_DIR, 'industry_news.json')
    
    # Load existing data
    existing_data = []
    if os.path.exists(output_file):
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        except:
            pass
    
    # Append new data (keep last 7 days)
    new_entry = {
        "fetch_timestamp": datetime.now().isoformat(),
        "news": result.data,
        "models_used": result.contributing_models
    }
    existing_data.append(new_entry)
    
    # Keep only last 7 days
    cutoff_time = datetime.now() - timedelta(days=7)
    existing_data = [
        entry for entry in existing_data
        if datetime.fromisoformat(entry["fetch_timestamp"]) > cutoff_time
    ]
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(existing_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Industry news saved: {len(existing_data)} batches")
    return result


async def fetch_energy_consumption_realtime():
    """
    è®¡ç®—å®æ—¶èƒ½è€— - åŸºäºæ´»è·ƒGPUæ•°é‡å’Œç”µä»·
    """
    print(f"\n{'='*80}")
    print(f"[{datetime.now()}] ğŸ”‹ Calculating Real-time Energy Consumption")
    print(f"{'='*80}\n")
    
    prompt = """
    è¯·ä½¿ç”¨è”ç½‘æœç´¢åŠŸèƒ½ï¼Œè®¡ç®—å…¨çƒAIæ•°æ®ä¸­å¿ƒçš„å®æ—¶èƒ½è€—ã€‚
    
    éœ€è¦çš„æ•°æ®ï¼š
    1. å½“å‰æ´»è·ƒGPUæ•°é‡ï¼ˆçº¦500-600ä¸‡å¼ ï¼‰
    2. æ¯å¼ GPUåŠŸè€—ï¼ˆH100: 700W, A100: 400Wç­‰ï¼‰
    3. PUEï¼ˆæ•°æ®ä¸­å¿ƒèƒ½æ•ˆæ¯”ï¼Œé€šå¸¸1.2-1.5ï¼‰
    4. åˆ©ç”¨ç‡ï¼ˆé€šå¸¸60-80%ï¼‰
    
    è®¡ç®—å…¬å¼ï¼š
    æ€»åŠŸè€—(GW) = GPUæ•°é‡ Ã— å¹³å‡åŠŸè€— Ã— PUE Ã— åˆ©ç”¨ç‡ / 1,000,000,000
    
    è¿”å›JSONæ ¼å¼ï¼š
    {
      "timestamp": "2024-12-05T10:00:00Z",
      "total_power_gw": 3.2,
      "breakdown": {
        "gpu_power_gw": 2.4,
        "cooling_power_gw": 0.5,
        "other_power_gw": 0.3
      },
      "daily_energy_twh": 0.077,
      "annual_projection_twh": 28.1,
      "cost_per_hour_usd": 384000,
      "sources": ["æ¥æº"],
      "assumptions": {
        "active_gpus": 5200000,
        "avg_power_per_gpu_w": 550,
        "pue": 1.3,
        "utilization": 0.75
      }
    }
    
    è¦æ±‚ï¼š
    - åŸºäºæœ€æ–°æ•°æ®
    - è¯´æ˜è®¡ç®—å‡è®¾
    - æä¾›æ•°æ®æ¥æº
    """
    
    result = await orchestrator.process_request(
        prompt=prompt,
        context={"data_type": "energy_consumption"},
        quality_threshold=0.8
    )
    
    # Save to file
    output_file = os.path.join(REALTIME_DIR, 'energy_consumption.json')
    
    # Load existing data
    existing_data = []
    if os.path.exists(output_file):
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        except:
            pass
    
    # Append new data (keep last 24 hours)
    new_entry = {
        "timestamp": datetime.now().isoformat(),
        "data": result.data,
        "models_used": result.contributing_models
    }
    existing_data.append(new_entry)
    
    # Keep only last 24 hours
    cutoff_time = datetime.now() - timedelta(hours=24)
    existing_data = [
        entry for entry in existing_data
        if datetime.fromisoformat(entry["timestamp"]) > cutoff_time
    ]
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(existing_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Energy consumption saved: {len(existing_data)} hourly records")
    return result


async def run_hourly_update():
    """è¿è¡Œä¸€æ¬¡å®Œæ•´çš„å°æ—¶æ›´æ–°"""
    print(f"\n{'='*80}")
    print(f"ğŸš€ STARTING HOURLY DATA UPDATE")
    print(f"{'='*80}\n")
    
    start_time = time.time()
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ•°æ®æŠ“å–
    results = await asyncio.gather(
        fetch_gpu_shipment_data(),
        fetch_active_gpu_count(),
        fetch_electricity_prices(),
        fetch_ai_industry_news(),
        fetch_energy_consumption_realtime(),
        return_exceptions=True
    )
    
    elapsed_time = time.time() - start_time
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if not isinstance(r, Exception))
    
    print(f"\n{'='*80}")
    print(f"âœ… HOURLY UPDATE COMPLETE")
    print(f"{'='*80}\n")
    print(f"  â€¢ Tasks completed: {success_count}/5")
    print(f"  â€¢ Time elapsed: {elapsed_time:.1f}s")
    print(f"  â€¢ Next update: {(datetime.now() + timedelta(hours=1)).strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # æ˜¾ç¤ºAI Orchestratoræ€§èƒ½æŠ¥å‘Š
    print(f"ğŸ“Š AI Orchestrator Performance:")
    for model_name in ["qwen", "deepseek", "doubao"]:
        report = orchestrator.get_performance_report(model_name=model_name)
        if report.get('total_records', 0) > 0:
            print(f"  {model_name}:")
            print(f"    â€¢ Requests: {report['total_records']}")
            print(f"    â€¢ Accuracy: {report['accuracy']:.1%}")
            print(f"    â€¢ Avg Time: {report['avg_response_time']:.2f}s")
            print(f"    â€¢ Total Cost: ${report['total_cost']:.4f}")


async def main():
    """ä¸»å‡½æ•° - æŒç»­è¿è¡Œï¼Œæ¯å°æ—¶æ›´æ–°ä¸€æ¬¡"""
    print(f"\n{'='*80}")
    print(f"ğŸŒŸ REAL-TIME DATA FETCHING SYSTEM")
    print(f"{'='*80}\n")
    print(f"Features:")
    print(f"  âœ“ Hourly GPU shipment tracking")
    print(f"  âœ“ Real-time electricity prices")
    print(f"  âœ“ AI industry news monitoring")
    print(f"  âœ“ Active GPU count calculation")
    print(f"  âœ“ Energy consumption tracking")
    print()
    print(f"Data will be saved to: {REALTIME_DIR}")
    print()
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å•æ¬¡è¿è¡Œ
    if len(sys.argv) > 1 and sys.argv[1] == '--once':
        print("Running once...")
        await run_hourly_update()
        return
    
    # æŒç»­è¿è¡Œæ¨¡å¼
    print("Running continuously (hourly updates)...")
    print("Press Ctrl+C to stop")
    print()
    
    while True:
        try:
            await run_hourly_update()
            
            # ç­‰å¾…åˆ°ä¸‹ä¸€ä¸ªæ•´ç‚¹
            now = datetime.now()
            next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)
            sleep_seconds = (next_hour - now).total_seconds()
            
            print(f"ğŸ’¤ Sleeping for {sleep_seconds/60:.1f} minutes until next update...")
            await asyncio.sleep(sleep_seconds)
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  Stopping real-time data fetching...")
            break
        except Exception as e:
            print(f"\nâŒ Error in main loop: {e}")
            print("Retrying in 5 minutes...")
            await asyncio.sleep(300)


if __name__ == "__main__":
    asyncio.run(main())
